# PathoLink

**PathoLink** is a multimodal learning framework designed to bridge **histopathological images** and **spatial/single-cell omics data**.  
It leverages **Transformer architectures** and a **Mixture-of-Experts (MoE)** mechanism to enable scalable, interpretable **cross-modal prediction** and **morphologyâ€“molecular alignment**.

> ðŸ§¬ This repository is the official implementation accompanying our paper *â€œPathoLink: Bridging Histopathology and Omics via Mixture-of-Experts Transformerâ€*, which is **currently under review**.  
> The code is under **active development**, and we will continue updating this repository with new modules and pretrained checkpoints â€” **stay tuned!**

---

## ðŸŒŸ Overview

In conventional models, predicting molecular expression (`Y`) from histology (`X`) is constrained by modality-specific redundancy.  
**PathoLink** introduces a synergistic information framework that learns a shared latent representation `Z` bridging both domains â€” reducing conditional uncertainty and enhancing predictive power:

\[
H(Y|X,Z) < H(Y|X)
\]

This design enables interpretable feature learning and robust cross-modal generation between tissue morphology and omics signals.

---

## ðŸ§© Repository Structure

```
PathoLink/
â”œâ”€â”€ Virchow2/              # Vision backbone (e.g., patch-level encoder)
â”œâ”€â”€ build/                 # Compiled extensions and build scripts
â”œâ”€â”€ cuda/                  # CUDA kernels for GPU acceleration
â”œâ”€â”€ dataset/HEST/          # Data loading and preprocessing (H&E + spatial transcriptomics)
â”œâ”€â”€ doc/                   # Documentation and supplementary notes
â”œâ”€â”€ fastmoe.egg-info/      # FastMoE package metadata
â”œâ”€â”€ fmoe/                  # Mixture-of-Experts (FastMoE) implementation
â”œâ”€â”€ scGPT/                 # scGPT integration for single-cell/omics representation
â”œâ”€â”€ tests/                 # Unit tests and reproducibility scripts
â”œâ”€â”€ MoE.py                 # Mixture of Experts model wrapper
â”œâ”€â”€ transformer.py         # Transformer architecture definition
â””â”€â”€ requirements.txt       # Dependencies
```

---

## âš™ï¸ Installation

```bash
git clone https://github.com/whytin/PathoLink.git
cd PathoLink

# (Recommended) Create a conda environment
conda create -n patholink python=3.9
conda activate patholink

# Install dependencies
pip install -r requirements.txt
```

---


## ðŸš€ Usage

## ðŸ§  Model Architecture

PathoLink integrates three main components:

1. **Virchow2** â€” Vision encoder for histopathological patches.  
2. **scGPT** â€” Pretrained omics encoder for molecular representation.  
3. **MoE-Transformer Fusion** â€” Multi-stage Transformer enhanced with **Mixture-of-Experts** routing for scalable cross-modal fusion and prediction.

The framework follows a synergistic information flow:
```
H&E Image (X) â†’ Latent Bridge (Z) â†’ Omics Prediction (Y)
```

---

## ðŸ§ª Development Status

- [x] Core model implementation 
- [x] scGPT integration
- [ ] Full training scripts
- [ ] Pretrained checkpoints
- [ ] Documentation and visualization tools

> ðŸ”§ *The codebase is being actively updated. Please watch or star the repository to get the latest updates.*

---

> ðŸ“¢ *PathoLink is under active development â€” follow the repository for upcoming updates, pretrained models, and experiment results!*
